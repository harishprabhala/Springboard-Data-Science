{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fb_percentiles = pd.read_excel('/Users/harishprabhala/Downloads/martinchek-2012-2016-facebook-posts/fb_posts_percentiles.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fb_percentiles['full_text'] = fb_percentiles['name'].map(str) + ' ' + fb_percentiles['message'].map(str) + ' ' + fb_percentiles['description'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [0,33,66,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_names = ['low','med','high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fb_percentiles_copy = fb_percentiles[['full_text','likes_count','shares_count','likes_percentile','shares_percentile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishprabhala/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/harishprabhala/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "fb_percentiles_copy['likes_percentile'] = fb_percentiles_copy['likes_percentile']*100\n",
    "fb_percentiles_copy['shares_percentile'] = fb_percentiles_copy['shares_percentile']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishprabhala/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "likes_categories = pd.cut(fb_percentiles_copy['likes_percentile'], bins, labels=group_names)\n",
    "fb_percentiles_copy['likes_class'] = likes_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishprabhala/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "fb_percentiles_copy['likes_class'] = fb_percentiles_copy['likes_class'].fillna('low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>shares_count</th>\n",
       "      <th>likes_percentile</th>\n",
       "      <th>shares_percentile</th>\n",
       "      <th>likes_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chief Justice Roberts Responds to Judicial Eth...</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With Reservations, Obama Signs Act to Allow De...</td>\n",
       "      <td>120</td>\n",
       "      <td>171</td>\n",
       "      <td>22.4</td>\n",
       "      <td>75.1</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wishes For 2012 to Fall on Times Square Some p...</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>58.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mitt Romney Vows to Veto Dream Act if Presiden...</td>\n",
       "      <td>140</td>\n",
       "      <td>23</td>\n",
       "      <td>29.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NY Pharmacy Shootout Leaves Suspect, ATF Agent...</td>\n",
       "      <td>59</td>\n",
       "      <td>34</td>\n",
       "      <td>5.1</td>\n",
       "      <td>26.9</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  likes_count  \\\n",
       "0  Chief Justice Roberts Responds to Judicial Eth...           61   \n",
       "1  With Reservations, Obama Signs Act to Allow De...          120   \n",
       "2  Wishes For 2012 to Fall on Times Square Some p...          271   \n",
       "3  Mitt Romney Vows to Veto Dream Act if Presiden...          140   \n",
       "4  NY Pharmacy Shootout Leaves Suspect, ATF Agent...           59   \n",
       "\n",
       "   shares_count  likes_percentile  shares_percentile likes_class  \n",
       "0            12               5.6                9.8         low  \n",
       "1           171              22.4               75.1         low  \n",
       "2             0              58.2                0.0         med  \n",
       "3            23              29.1               18.7         low  \n",
       "4            34               5.1               26.9         low  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_percentiles_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low     169715\n",
       "med     167276\n",
       "high    165823\n",
       "Name: likes_class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_percentiles_copy['likes_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishprabhala/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/harishprabhala/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import gensim.parsing.preprocessing as process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess (line):\n",
    "    line = re.sub(r\"http\\S+\", \"\", line)\n",
    "    line = line.lower()\n",
    "    line = process.remove_stopwords(line)\n",
    "    line = process.strip_numeric(line)\n",
    "    line = process.strip_punctuation(line)\n",
    "    line = process.strip_short(line)\n",
    "    line = process.strip_multiple_whitespaces(line)\n",
    "    tokens = sent_tokenize(line)\n",
    "    stemmed = [w for w in tokens if lemmatizer.lemmatize(w)] \n",
    "    return ' '.join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "for w in fb_percentiles_copy['full_text']:\n",
    "    text.append(preprocess(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = text, fb_percentiles_copy['likes_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_1 = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = SelectKBest(chi2, k=10000).fit_transform(X_1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502814, 10000)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_new, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((336885, 10000), (165929, 10000), (336885,), (165929,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test data:  0.489034466549\n",
      "Accuracy of training data:  0.521097703964\n",
      "\n",
      "\n",
      "Classification report summary of Multinomial Logistic Regression\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.58      0.52      0.55     61437\n",
      "        low       0.58      0.51      0.54     63578\n",
      "        med       0.30      0.41      0.35     40914\n",
      "\n",
      "avg / total       0.51      0.49      0.50    165929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit=LogisticRegression(multi_class='multinomial', solver='sag',C=0.1)\n",
    "logit.fit(X_train,Y_train)\n",
    "print ('Accuracy of test data: ',(accuracy_score(logit.predict(X_test), Y_test)))\n",
    "print ('Accuracy of training data: ',(accuracy_score(logit.predict(X_train), Y_train)))\n",
    "print(\"\\n\")\n",
    "print ('Classification report summary of Multinomial Logistic Regression')\n",
    "print(classification_report(logit.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test data:  0.483670726636\n",
      "Accuracy of training data:  0.497908781929\n",
      "\n",
      "\n",
      "Classification report summary of MultinomialNB with alpha = 0.01:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.62      0.49      0.55     68662\n",
      "        low       0.55      0.52      0.53     59675\n",
      "        med       0.28      0.41      0.33     37592\n",
      "\n",
      "avg / total       0.52      0.48      0.50    165929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf2=MultinomialNB(alpha=0.01)\n",
    "clf2.fit(X_train,Y_train)\n",
    "print ('Accuracy of test data: ',(accuracy_score(clf2.predict(X_test), Y_test)))\n",
    "print ('Accuracy of training data: ',(accuracy_score(clf2.predict(X_train), Y_train)))\n",
    "print(\"\\n\")\n",
    "print ('Classification report summary of MultinomialNB with alpha = 0.01:')\n",
    "print(classification_report(clf2.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
